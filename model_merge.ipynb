{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 模型融合目标\n",
    "- 对于多种 调参完成的模型 进行 模型融合\n",
    "- 完成对于多种模型的融合，提交结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 内容介绍<br>\n",
    "模型融合是比赛后期的一个重要环节，大体来说有如下的类型方式\n",
    "\n",
    "1、简单加权融合\n",
    "- 回归（分类概率）：算数平均融合（Arithmetic mean）,几何平均融合（Geometric mean）\n",
    "- 分类：投票\n",
    "- 综合：排序融合（rank averaging）,log融合\n",
    "\n",
    "2、stacking/blending:\n",
    "- 构建多层模型，并利用预测结果再拟合预测\n",
    "\n",
    "3、boosting/bagging(在xgboost,Adaboost,GBDT中已经遇到)：\n",
    "- 多树提升方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 stacking 相关理论介绍\n",
    "\n",
    "（1）什么是stacking\n",
    "\n",
    "Step1:\n",
    "\n",
    "用训练集学习出 若干基学习器\n",
    "\n",
    "Step2:\n",
    "\n",
    "用学习器的预测结果做为新的训练集，来学习一个新的学习器\n",
    "\n",
    "![jupyter](./pic/stacking.png)\n",
    "**结合策略**\n",
    "将个体学习器结合在一起的时候使用的方法叫做结合策略。\n",
    "- 对于分类问题：使用投票法选择输出最多的类\n",
    "- 对于回归问题：将多分类器结果求平均值\n",
    "- 用另外一个 机器学习算法 将 个体机器学习器 的结果结合在一起，这就是Stacking\n",
    "\n",
    "在stacking方法中，将个体学习器叫做**初级学习器**，用于结合的学习器叫做**次级学习器**或**元学习器**（meta-learner）,次级学习器用于训练的数据叫做**次级训练集**\n",
    "\n",
    "次级训练集是在训练集上用初级学习器得到的\n",
    "\n",
    "（2） 如何进行stacking\n",
    "\n",
    "算法示意图如下：\n",
    "\n",
    "![jupyter](./pic/stacking_alg.png)\n",
    "\n",
    "- 过程1—3是训练出T个个体学习器，也就是初级学习器\n",
    "- 过程5—9是使用训练出来的个体学习器来得预测的结果，这个预测结果当做次级学习器的训练集\n",
    "- 过程11是用初级学习器预测的结果训练出次级学习器，得到我们最后训练的模型\n",
    "\n",
    "（3）stacking方法讲解：\n",
    "\n",
    "详细见https://tianchi.aliyun.com/notebook-ai/detail?spm=5176.12281978.0.0.68021b438BRm0A&postId=95535\n",
    "\n",
    "   Stacking本质上就是这么直接的思路，但是直接这样有时对于如果训练集和测试集分布不那么一致的情况下是有一点问题的，其问题在于用初始模型训练的标签再利用真实标签进行再训练，毫无疑问会导致一定的模型过拟合训练集，这样或许模型在测试集上的泛化能力或者说效果会有一定的下降，因此现在的问题变成了如何降低再训练的过拟合性，这里我们一般有两种方法。\n",
    "\n",
    "- 次级模型尽量选择简单的线性模型\n",
    "- 利用K折交叉验证\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4代码示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.1 回归/分类概率融合\n",
    "（1）简单加权平均，结果直接融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 生成一些简单的样本数据，test_prei 代表第i个模型的预测值\n",
    "test_pre1 = [1.2, 3.2, 2.1, 6.2]\n",
    "test_pre2 = [0.9, 3.1, 2.0, 5.9]\n",
    "test_pre3 = [1.1, 2.9, 2.2, 6.0]\n",
    "\n",
    "# y_test_true 代表模型的真实值\n",
    "y_test_true = [1, 3, 2, 6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#定义结果的加权平均函数\n",
    "def Weighted_mothod(test_pre1, test_pre2, test_pre3, w = [1/3, 1/3, 1/3]):\n",
    "    Weighted_result = w[0] * pd.Series(test_pre1) + w[1] * pd.Series(test_pre2) + w[2] * pd.Series(test_pre3)\n",
    "    return Weighted_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred1 MAE: 0.1750000000000001\n",
      "Pred2 MAE: 0.07499999999999993\n",
      "Pred3 MAE: 0.10000000000000009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "# 各模型的结果计算MAE\n",
    "print('Pred1 MAE:',MAE(y_test_true, test_pre1))\n",
    "print('Pred2 MAE:',MAE(y_test_true, test_pre2))\n",
    "print('Pred3 MAE:',MAE(y_test_true, test_pre3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight_pre MAE 0.05750000000000027\n"
     ]
    }
   ],
   "source": [
    "## 根据加权计算MAE\n",
    "w = [0.3, 0.4, 0.3]# 定义比重权值\n",
    "Weighted_pre = Weighted_mothod(test_pre1, test_pre2, test_pre3, w)\n",
    "print('Weight_pre MAE', MAE(y_test_true, Weighted_pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现结果有所提升，这就是简单的加权平均"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有一些特殊的形式，比如mean平均，median平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mean_method(test_pre1, test_pre2, test_pre3):\n",
    "    Mean_result = pd.concat([pd.Series(test_pre1),pd.Series(test_pre2),pd.Series(test_pre3)],axis=1).mean(axis = 1)\n",
    "    return Mean_result\n",
    "# axis = 0按照列，axis = 1按照行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_pre MAE: 0.06666666666666693\n"
     ]
    }
   ],
   "source": [
    "Mean_pre = Mean_method(test_pre1,test_pre2,test_pre3)\n",
    "print('Mean_pre MAE:',MAE(y_test_true, Mean_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  1.2  0.9  1.1\n",
       "1  3.2  3.1  2.9\n",
       "2  2.1  2.0  2.2\n",
       "3  6.2  5.9  6.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#原来的\n",
    "def Median_method(test_pre1,test_pre2,test_pre3):\n",
    "    Median_result = pd.concat([pd.Series(test_pre1),pd.Series(test_pre2),pd.Series(test_pre3)],axis=1)\n",
    "    return Median_result\n",
    "\n",
    "Median_method(test_pre1,test_pre2,test_pre3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.1\n",
       "1    3.1\n",
       "2    2.1\n",
       "3    6.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 定义结果的加权平均函数\n",
    "def Median_method(test_pre1,test_pre2,test_pre3):\n",
    "    Median_result = pd.concat([pd.Series(test_pre1),pd.Series(test_pre2),pd.Series(test_pre3)],axis=1).median(axis=1)\n",
    "    return Median_result\n",
    "\n",
    "Median_method(test_pre1,test_pre2,test_pre3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median_pre MAE: 0.07500000000000007\n"
     ]
    }
   ],
   "source": [
    "Median_pre = Median_method(test_pre1,test_pre2,test_pre3)\n",
    "print('Median_pre MAE:',MAE(y_test_true, Median_pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）Stacking 融合（回归）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def Stacking_method(train_reg1, train_reg2, train_reg3, y_train_true, test_pre1, test_pre2, test_pre3, model_L2 = linear_model.LinearRegression()):\n",
    "    model_L2.fit(pd.concat([pd.Series(train_reg1),pd.Series(train_reg2),pd.Series(train_reg3)],axis=1).values,y_train_true)\n",
    "    Stacking_result = model_L2.predict(pd.concat([pd.Series(test_pre1),pd.Series(test_pre2),pd.Series(test_pre3)],axis=1).values)\n",
    "    return Stacking_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 生成一些简单的样本数据，test_prei 代表第i个模型的预测值\n",
    "train_reg1 = [3.2, 8.2, 9.1, 5.2]\n",
    "train_reg2 = [2.9, 8.1, 9.0, 4.9]\n",
    "train_reg3 = [3.1, 7.9, 9.2, 5.0]\n",
    "# y_test_true 代表第模型的真实值\n",
    "y_train_true = [3, 8, 9, 5] \n",
    "\n",
    "test_pre1 = [1.2, 3.2, 2.1, 6.2]\n",
    "test_pre2 = [0.9, 3.1, 2.0, 5.9]\n",
    "test_pre3 = [1.1, 2.9, 2.2, 6.0]\n",
    "\n",
    "# y_test_true 代表第模型的真实值\n",
    "y_test_true = [1, 3, 2, 6] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking_pre MAE: 0.042134831460675204\n"
     ]
    }
   ],
   "source": [
    "model_L2= linear_model.LinearRegression()\n",
    "Stacking_pre = Stacking_method(train_reg1,train_reg2,train_reg3,y_train_true,\n",
    "                               test_pre1,test_pre2,test_pre3,model_L2)\n",
    "print('Stacking_pre MAE:',MAE(y_test_true, Stacking_pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现模型结果相对于之前有进一步的提升，这是我们需要注意的一点是，对于第二层Stacking的模型不宜选取的过于复杂，这样会导致模型在训练集上过拟合，从而使得在测试集上并不能达到很好的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.4.2 分类模型融合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于分类，同样可以使用融合方法，如简单投票，Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1)Voting投票机制：\n",
    "\n",
    "Voting即投票机制，分为软投票和硬投票两种，其原理采用少数服从多数的思想。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n",
      "Accuracy: 0.96 (+/- 0.02) [XGBBoosting]\n",
      "Accuracy: 0.33 (+/- 0.00) [Random Forest]\n",
      "Accuracy: 0.92 (+/- 0.03) [SVM]\n",
      "Accuracy: 0.91 (+/- 0.02) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "硬投票：对多各模型直接进行投票，不区分模型对结果的相对重要度，最终投票数目最多的类\n",
    "为最终被预测的类\n",
    "'''\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)\n",
    "\n",
    "\n",
    "clf1 = XGBClassifier(learning_rate=0.1, n_estimators=150, max_depth=3, min_child_weight=2, subsample=0.7,\n",
    "                     colsample_bytree=0.6, objective='binary:logistic')\n",
    "clf2 = RandomForestClassifier(n_estimators=50, max_depth=1, min_samples_split=4,\n",
    "                              min_samples_leaf=63,oob_score=True)\n",
    "clf3 = SVC(C=0.1)\n",
    "\n",
    "# 硬投票\n",
    "eclf = VotingClassifier(estimators=[('xgb', clf1), ('rf', clf2), ('svc', clf3)], voting='hard')\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['XGBBoosting', 'Random Forest', 'SVM', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, x, y, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'F:\\\\anaconda\\\\envs\\\\han\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96 (+/- 0.02) [XGBBoosting]\n",
      "Accuracy: 0.33 (+/- 0.00) [Random Forest]\n",
      "Accuracy: 0.92 (+/- 0.03) [SVM]\n",
      "Accuracy: 0.96 (+/- 0.02) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "软投票：和硬投票原理相同，增加了设置权重的功能，可以为不同模型设置不同权重，进而区别模型不同的重要度。\n",
    "'''\n",
    "x=iris.data\n",
    "y=iris.target\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)\n",
    "\n",
    "clf1 = XGBClassifier(learning_rate=0.1, n_estimators=150, max_depth=3, min_child_weight=2, subsample=0.8,\n",
    "                     colsample_bytree=0.8, objective='binary:logistic')\n",
    "clf2 = RandomForestClassifier(n_estimators=50, max_depth=1, min_samples_split=4,\n",
    "                              min_samples_leaf=63,oob_score=True)\n",
    "clf3 = SVC(C=0.1, probability=True)\n",
    "\n",
    "# 软投票\n",
    "eclf = VotingClassifier(estimators=[('xgb', clf1), ('rf', clf2), ('svc', clf3)], voting='soft', weights=[2, 1, 1])\n",
    "clf1.fit(x_train, y_train)\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['XGBBoosting', 'Random Forest', 'SVM', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, x, y, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2)分类的stacking/Blending 融合\n",
    "\n",
    "stacking是一种分层模型集成框架。\n",
    "\n",
    "以两层为例，第一层由多个基学习器组成，其输入为原始训练集，第二层的模型则是以第一层基学习器的输出作为训练集进行再训练，从而得到完整的stacking模型, stacking两层模型都使用了全部的训练数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val auc Score: 1.000000\n",
      "val auc Score: 0.500000\n",
      "val auc Score: 0.500000\n",
      "val auc Score: 0.500000\n",
      "val auc Score: 0.500000\n",
      "Val auc Score of Stacking: 1.000000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "5-Fold Stacking\n",
    "'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier,GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "#创建训练的数据集\n",
    "data_0 = iris.data\n",
    "data = data_0[:100,:]\n",
    "\n",
    "target_0 = iris.target\n",
    "target = target_0[:100]\n",
    "\n",
    "#模型融合中使用到的各个单模型\n",
    "clfs = [LogisticRegression(solver='lbfgs'),\n",
    "        RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
    "        ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
    "        ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),\n",
    "        GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=5)]\n",
    " \n",
    "#切分一部分数据作为测试集\n",
    "X, X_predict, y, y_predict = train_test_split(data, target, test_size=0.3, random_state=2020)\n",
    "\n",
    "dataset_blend_train = np.zeros((X.shape[0], len(clfs)))\n",
    "dataset_blend_test = np.zeros((X_predict.shape[0], len(clfs)))\n",
    "\n",
    "#5折stacking\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits)\n",
    "skf = skf.split(X, y)\n",
    "\n",
    "for j, clf in enumerate(clfs):\n",
    "    #依次训练各个单模型\n",
    "    dataset_blend_test_j = np.zeros((X_predict.shape[0], 5))\n",
    "    for i, (train, test) in enumerate(skf):\n",
    "        #5-Fold交叉训练，使用第i个部分作为预测，剩余的部分来训练模型，获得其预测的输出作为第i部分的新特征。\n",
    "        X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_submission = clf.predict_proba(X_test)[:, 1]\n",
    "        dataset_blend_train[test, j] = y_submission\n",
    "        dataset_blend_test_j[:, i] = clf.predict_proba(X_predict)[:, 1]\n",
    "    #对于测试集，直接用这k个模型的预测值均值作为新的特征。\n",
    "    dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)\n",
    "    print(\"val auc Score: %f\" % roc_auc_score(y_predict, dataset_blend_test[:, j]))\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf.fit(dataset_blend_train, y)\n",
    "y_submission = clf.predict_proba(dataset_blend_test)[:, 1]\n",
    "\n",
    "print(\"Val auc Score of Stacking: %f\" % (roc_auc_score(y_predict, y_submission)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blending，其实和Stacking是一种类似的多层模型融合的形式\n",
    "\n",
    "其主要思路是把原始的训练集先分成两部分，比如70%的数据作为新的训练集，剩下30%的数据作为测试集。\n",
    "\n",
    "在第一层，我们在这70%的数据上训练多个模型，然后去预测那30%数据的label，同时也预测test集的label。\n",
    "\n",
    "在第二层，我们就直接用这30%数据在第一层预测的结果做为新特征继续训练，然后用test集第一层预测的label做特征，用第二层训练的模型做进一步预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其优点在于：\n",
    "\n",
    "1.比stacking简单（因为不用进行k次的交叉验证来获得stacker feature）\n",
    "\n",
    "2.避开了一个信息泄露问题：generlizers和stacker使用了不一样的数据集\n",
    "缺点在于：\n",
    "\n",
    "1.使用了很少的数据（第二阶段的blender只使用training set10%的量）\n",
    "\n",
    "2.blender可能会过拟合\n",
    "\n",
    "3.stacking使用多次的交叉验证会比较稳健 '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val auc Score: 1.000000\n",
      "val auc Score: 1.000000\n",
      "val auc Score: 1.000000\n",
      "val auc Score: 1.000000\n",
      "val auc Score: 1.000000\n",
      "Val auc Score of Blending: 1.000000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Blending\n",
    "'''\n",
    " \n",
    "#创建训练的数据集\n",
    "#创建训练的数据集\n",
    "data_0 = iris.data\n",
    "data = data_0[:100,:]\n",
    "\n",
    "target_0 = iris.target\n",
    "target = target_0[:100]\n",
    " \n",
    "#模型融合中使用到的各个单模型\n",
    "clfs = [LogisticRegression(solver='lbfgs'),\n",
    "        RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
    "        RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),\n",
    "        ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
    "        #ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),\n",
    "        GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=5)]\n",
    " \n",
    "#切分一部分数据作为测试集\n",
    "X, X_predict, y, y_predict = train_test_split(data, target, test_size=0.3, random_state=2020)\n",
    "\n",
    "#切分训练数据集为d1,d2两部分\n",
    "X_d1, X_d2, y_d1, y_d2 = train_test_split(X, y, test_size=0.5, random_state=2020)\n",
    "dataset_d1 = np.zeros((X_d2.shape[0], len(clfs)))\n",
    "dataset_d2 = np.zeros((X_predict.shape[0], len(clfs)))\n",
    " \n",
    "for j, clf in enumerate(clfs):\n",
    "    #依次训练各个单模型\n",
    "    clf.fit(X_d1, y_d1)\n",
    "    y_submission = clf.predict_proba(X_d2)[:, 1]\n",
    "    dataset_d1[:, j] = y_submission\n",
    "    #对于测试集，直接用这k个模型的预测值作为新的特征。\n",
    "    dataset_d2[:, j] = clf.predict_proba(X_predict)[:, 1]\n",
    "    print(\"val auc Score: %f\" % roc_auc_score(y_predict, dataset_d2[:, j]))\n",
    "\n",
    "#融合使用的模型\n",
    "clf = GradientBoostingClassifier(learning_rate=0.02, subsample=0.5, max_depth=6, n_estimators=30)\n",
    "clf.fit(dataset_d1, y_d2)\n",
    "y_submission = clf.predict_proba(dataset_d2)[:, 1]\n",
    "print(\"Val auc Score of Blending: %f\" % (roc_auc_score(y_predict, y_submission)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3)分类Stacking的融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91 (+/- 0.01) [KNN]\n",
      "Accuracy: 0.95 (+/- 0.01) [Random Forest]\n",
      "Accuracy: 0.91 (+/- 0.02) [Naive Bayes]\n",
      "Accuracy: 0.95 (+/- 0.02) [Stacking Classifier]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import itertools\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from mlxtend.plotting import plot_learning_curves\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "# 以python自带的鸢尾花数据集为例\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data[:, 1:3], iris.target\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], \n",
    "                          meta_classifier=lr)\n",
    "\n",
    "label = ['KNN', 'Random Forest', 'Naive Bayes', 'Stacking Classifier']\n",
    "clf_list = [clf1, clf2, clf3, sclf]\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "grid = itertools.product([0,1],repeat=2)\n",
    "\n",
    "clf_cv_mean = []\n",
    "clf_cv_std = []\n",
    "for clf, label, grd in zip(clf_list, label, grid):\n",
    "        \n",
    "    scores = cross_val_score(clf, X, y, cv=3, scoring='accuracy')\n",
    "    print(\"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label))\n",
    "    clf_cv_mean.append(scores.mean())\n",
    "    clf_cv_std.append(scores.std())\n",
    "        \n",
    "    clf.fit(X, y)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X=X, y=y, clf=clf)\n",
    "    plt.title(label)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现 基模型 用 'KNN', 'Random Forest', 'Naive Bayes' 然后再这基础上 次级模型加一个 'LogisticRegression'，模型测试效果有着很好的提升。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.4.3 一些其他方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将特征放进模型中预测，并将预测结果变换并作为新的特征加入原有特征中再经过模型预测结果 （Stacking变化）¶\n",
    "（可以反复预测多次将结果加入最后的特征中）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ensemble_add_feature(train,test,target,clfs):\n",
    "    \n",
    "    # n_flods = 5\n",
    "    # skf = list(StratifiedKFold(y, n_folds=n_flods))\n",
    "\n",
    "    train_ = np.zeros((train.shape[0],len(clfs*2)))\n",
    "    test_ = np.zeros((test.shape[0],len(clfs*2)))\n",
    "\n",
    "    for j,clf in enumerate(clfs):\n",
    "        '''依次训练各个单模型'''\n",
    "        # print(j, clf)\n",
    "        '''使用第1个部分作为预测，第2部分来训练模型，获得其预测的输出作为第2部分的新特征。'''\n",
    "        # X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]\n",
    "\n",
    "        clf.fit(train,target)\n",
    "        y_train = clf.predict(train)\n",
    "        y_test = clf.predict(test)\n",
    "\n",
    "        ## 新特征生成\n",
    "        train_[:,j*2] = y_train**2\n",
    "        test_[:,j*2] = y_test**2\n",
    "        train_[:, j+1] = np.exp(y_train)\n",
    "        test_[:, j+1] = np.exp(y_test)\n",
    "        # print(\"val auc Score: %f\" % r2_score(y_predict, dataset_d2[:, j]))\n",
    "        print('Method ',j)\n",
    "    \n",
    "    train_ = pd.DataFrame(train_)\n",
    "    test_ = pd.DataFrame(test_)\n",
    "    return train_,test_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method  0\n",
      "Method  1\n",
      "Method  2\n",
      "Method  3\n",
      "Method  4\n",
      "Val auc Score of stacking: 1.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "\n",
    "data_0 = iris.data\n",
    "data = data_0[:100,:]\n",
    "\n",
    "target_0 = iris.target\n",
    "target = target_0[:100]\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(data,target,test_size=0.3)\n",
    "x_train = pd.DataFrame(x_train) ; x_test = pd.DataFrame(x_test)\n",
    "\n",
    "#模型融合中使用到的各个单模型\n",
    "clfs = [LogisticRegression(),\n",
    "        RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
    "        ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
    "        ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),\n",
    "        GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=5)]\n",
    "\n",
    "New_train,New_test = Ensemble_add_feature(x_train,x_test,y_train,clfs)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "# clf = GradientBoostingClassifier(learning_rate=0.02, subsample=0.5, max_depth=6, n_estimators=30)\n",
    "clf.fit(New_train, y_train)\n",
    "y_emb = clf.predict_proba(New_test)[:, 1]\n",
    "\n",
    "print(\"Val auc Score of stacking: %f\" % (roc_auc_score(y_test, y_emb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.4.4 赛题示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "import itertools\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "# from mlxtend.plotting import plot_learning_curves\n",
    "# from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA,FastICA,FactorAnalysis,SparsePCA\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 31)\n",
      "(50000, 30)\n"
     ]
    }
   ],
   "source": [
    "## 数据读取\n",
    "Train_data = pd.read_csv('../data/used_car_train_20200313.csv', sep=' ')\n",
    "TestA_data = pd.read_csv('../data/used_car_testA_20200313.csv', sep=' ')\n",
    "\n",
    "print(Train_data.shape)\n",
    "print(TestA_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>name</th>\n",
       "      <th>regDate</th>\n",
       "      <th>model</th>\n",
       "      <th>brand</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>kilometer</th>\n",
       "      <th>...</th>\n",
       "      <th>v_5</th>\n",
       "      <th>v_6</th>\n",
       "      <th>v_7</th>\n",
       "      <th>v_8</th>\n",
       "      <th>v_9</th>\n",
       "      <th>v_10</th>\n",
       "      <th>v_11</th>\n",
       "      <th>v_12</th>\n",
       "      <th>v_13</th>\n",
       "      <th>v_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>736</td>\n",
       "      <td>20040402</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>12.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235676</td>\n",
       "      <td>0.101988</td>\n",
       "      <td>0.129549</td>\n",
       "      <td>0.022816</td>\n",
       "      <td>0.097462</td>\n",
       "      <td>-2.881803</td>\n",
       "      <td>2.804097</td>\n",
       "      <td>-2.420821</td>\n",
       "      <td>0.795292</td>\n",
       "      <td>0.914762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2262</td>\n",
       "      <td>20030301</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264777</td>\n",
       "      <td>0.121004</td>\n",
       "      <td>0.135731</td>\n",
       "      <td>0.026597</td>\n",
       "      <td>0.020582</td>\n",
       "      <td>-4.900482</td>\n",
       "      <td>2.096338</td>\n",
       "      <td>-1.030483</td>\n",
       "      <td>-1.722674</td>\n",
       "      <td>0.245522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14874</td>\n",
       "      <td>20040403</td>\n",
       "      <td>115.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163</td>\n",
       "      <td>12.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251410</td>\n",
       "      <td>0.114912</td>\n",
       "      <td>0.165147</td>\n",
       "      <td>0.062173</td>\n",
       "      <td>0.027075</td>\n",
       "      <td>-4.846749</td>\n",
       "      <td>1.803559</td>\n",
       "      <td>1.565330</td>\n",
       "      <td>-0.832687</td>\n",
       "      <td>-0.229963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>71865</td>\n",
       "      <td>19960908</td>\n",
       "      <td>109.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>193</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274293</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>0.121964</td>\n",
       "      <td>0.033395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.509599</td>\n",
       "      <td>1.285940</td>\n",
       "      <td>-0.501868</td>\n",
       "      <td>-2.438353</td>\n",
       "      <td>-0.478699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>111080</td>\n",
       "      <td>20120103</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228036</td>\n",
       "      <td>0.073205</td>\n",
       "      <td>0.091880</td>\n",
       "      <td>0.078819</td>\n",
       "      <td>0.121534</td>\n",
       "      <td>-1.896240</td>\n",
       "      <td>0.910783</td>\n",
       "      <td>0.931110</td>\n",
       "      <td>2.834518</td>\n",
       "      <td>1.923482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SaleID    name   regDate  model  brand  bodyType  fuelType  gearbox  power  \\\n",
       "0       0     736  20040402   30.0      6       1.0       0.0      0.0     60   \n",
       "1       1    2262  20030301   40.0      1       2.0       0.0      0.0      0   \n",
       "2       2   14874  20040403  115.0     15       1.0       0.0      0.0    163   \n",
       "3       3   71865  19960908  109.0     10       0.0       0.0      1.0    193   \n",
       "4       4  111080  20120103  110.0      5       1.0       0.0      0.0     68   \n",
       "\n",
       "   kilometer  ...       v_5       v_6       v_7       v_8       v_9      v_10  \\\n",
       "0       12.5  ...  0.235676  0.101988  0.129549  0.022816  0.097462 -2.881803   \n",
       "1       15.0  ...  0.264777  0.121004  0.135731  0.026597  0.020582 -4.900482   \n",
       "2       12.5  ...  0.251410  0.114912  0.165147  0.062173  0.027075 -4.846749   \n",
       "3       15.0  ...  0.274293  0.110300  0.121964  0.033395  0.000000 -4.509599   \n",
       "4        5.0  ...  0.228036  0.073205  0.091880  0.078819  0.121534 -1.896240   \n",
       "\n",
       "       v_11      v_12      v_13      v_14  \n",
       "0  2.804097 -2.420821  0.795292  0.914762  \n",
       "1  2.096338 -1.030483 -1.722674  0.245522  \n",
       "2  1.803559  1.565330 -0.832687 -0.229963  \n",
       "3  1.285940 -0.501868 -2.438353 -0.478699  \n",
       "4  0.910783  0.931110  2.834518  1.923482  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SaleID', 'name', 'regDate', 'model', 'brand', 'bodyType', 'fuelType',\n",
      "       'gearbox', 'power', 'kilometer', 'regionCode', 'seller', 'offerType',\n",
      "       'creatDate', 'price', 'v_0', 'v_1', 'v_2', 'v_3', 'v_4', 'v_5', 'v_6',\n",
      "       'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12', 'v_13', 'v_14'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "numerical_cols = Train_data.select_dtypes(exclude = 'object').columns\n",
    "print(numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in numerical_cols if col not in ['SaleID','name','regDate','price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (150000, 26)\n",
      "X test shape: (50000, 26)\n"
     ]
    }
   ],
   "source": [
    "X_data = Train_data[feature_cols]\n",
    "Y_data = Train_data['price']\n",
    "\n",
    "X_test  = TestA_data[feature_cols]\n",
    "\n",
    "print('X train shape:',X_data.shape)\n",
    "print('X test shape:',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sta_inf(data):\n",
    "    print('_min',np.min(data))\n",
    "    print('_max:',np.max(data))\n",
    "    print('_mean',np.mean(data))\n",
    "    print('_ptp',np.ptp(data))\n",
    "    print('_std',np.std(data))\n",
    "    print('_var',np.var(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sta of label:\n",
      "_min 11\n",
      "_max: 99999\n",
      "_mean 5923.327333333334\n",
      "_ptp 99988\n",
      "_std 7501.973469876635\n",
      "_var 56279605.942732885\n"
     ]
    }
   ],
   "source": [
    "print('Sta of label:')\n",
    "Sta_inf(Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X_data.fillna(-1)\n",
    "X_test = X_test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_lr(x_train,y_train):\n",
    "    reg_model = linear_model.LinearRegression()\n",
    "    reg_model.fit(x_train,y_train)\n",
    "    return reg_model\n",
    "\n",
    "def build_model_ridge(x_train,y_train):\n",
    "    reg_model = linear_model.Ridge(alpha=0.8)#alphas=range(1,100,5)\n",
    "    reg_model.fit(x_train,y_train)\n",
    "    return reg_model\n",
    "\n",
    "def build_model_lasso(x_train,y_train):\n",
    "    reg_model = linear_model.LassoCV()\n",
    "    reg_model.fit(x_train,y_train)\n",
    "    return reg_model\n",
    "\n",
    "def build_model_gbdt(x_train,y_train):\n",
    "    estimator =GradientBoostingRegressor(loss='ls',subsample= 0.85,max_depth= 5,n_estimators = 100)\n",
    "    param_grid = { \n",
    "            'learning_rate': [0.05,0.08,0.1,0.2],\n",
    "            }\n",
    "    gbdt = GridSearchCV(estimator, param_grid,cv=3)\n",
    "    gbdt.fit(x_train,y_train)\n",
    "    print(gbdt.best_params_)\n",
    "    # print(gbdt.best_estimator_ )\n",
    "    return gbdt\n",
    "\n",
    "def build_model_xgb(x_train,y_train):\n",
    "    model = xgb.XGBRegressor(n_estimators=120, learning_rate=0.08, gamma=0, subsample=0.8,\\\n",
    "        colsample_bytree=0.9, max_depth=5) #, objective ='reg:squarederror'\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def build_model_lgb(x_train,y_train):\n",
    "    estimator = lgb.LGBMRegressor(num_leaves=63,n_estimators = 100)\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "    }\n",
    "    gbm = GridSearchCV(estimator, param_grid)\n",
    "    gbm.fit(x_train, y_train)\n",
    "    return gbm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2)XGBoost的五折交叉回归验证实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mae: 594.8909340395033\n",
      "Val mae 693.382067947197\n"
     ]
    }
   ],
   "source": [
    "## xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "xgr = xgb.XGBRegressor(n_estimators=120, learning_rate=0.1, subsample=0.8,\\\n",
    "        colsample_bytree=0.9, max_depth=7) # ,objective ='reg:squarederror'\n",
    "\n",
    "scores_train = []\n",
    "scores = []\n",
    "\n",
    "## 5折交叉验证方式\n",
    "sk=StratifiedKFold(n_splits=5,shuffle=True,random_state=0)\n",
    "for train_ind,val_ind in sk.split(X_data,Y_data):\n",
    "    \n",
    "    train_x=X_data.iloc[train_ind].values\n",
    "    train_y=Y_data.iloc[train_ind]\n",
    "    val_x=X_data.iloc[val_ind].values\n",
    "    val_y=Y_data.iloc[val_ind]\n",
    "    \n",
    "    xgr.fit(train_x,train_y)\n",
    "    pred_train_xgb=xgr.predict(train_x)\n",
    "    pred_xgb=xgr.predict(val_x)\n",
    "    \n",
    "    score_train = mean_absolute_error(train_y,pred_train_xgb)\n",
    "    scores_train.append(score_train)\n",
    "    score = mean_absolute_error(val_y,pred_xgb)\n",
    "    scores.append(score)\n",
    "\n",
    "print('Train mae:',np.mean(score_train))\n",
    "print('Val mae',np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3)划分数据集， 并用多种方法训练和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict LR...\n",
      "Predict Ridge...\n",
      "Predict Lasso...\n",
      "Predict GBDT...\n",
      "{'learning_rate': 0.2}\n"
     ]
    }
   ],
   "source": [
    "## Split data with val\n",
    "x_train,x_val,y_train,y_val = train_test_split(X_data,Y_data,test_size=0.3)\n",
    "\n",
    "## Train and Predict\n",
    "print('Predict LR...')\n",
    "model_lr = build_model_lr(x_train,y_train)\n",
    "val_lr = model_lr.predict(x_val)\n",
    "subA_lr = model_lr.predict(X_test)\n",
    "\n",
    "print('Predict Ridge...')\n",
    "model_ridge = build_model_ridge(x_train,y_train)\n",
    "val_ridge = model_ridge.predict(x_val)\n",
    "subA_ridge = model_ridge.predict(X_test)\n",
    "\n",
    "print('Predict Lasso...')\n",
    "model_lasso = build_model_lasso(x_train,y_train)\n",
    "val_lasso = model_lasso.predict(x_val)\n",
    "subA_lasso = model_lasso.predict(X_test)\n",
    "\n",
    "print('Predict GBDT...')\n",
    "model_gbdt = build_model_gbdt(x_train,y_train)\n",
    "val_gbdt = model_gbdt.predict(x_val)\n",
    "subA_gbdt = model_gbdt.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般比赛中效果最为显著的两种方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict XGB...\n",
      "predict lgb...\n"
     ]
    }
   ],
   "source": [
    "print('predict XGB...')\n",
    "model_xgb = build_model_xgb(x_train,y_train)\n",
    "val_xgb = model_xgb.predict(x_val)\n",
    "subA_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "print('predict lgb...')\n",
    "model_lgb = build_model_lgb(x_train,y_train)\n",
    "val_lgb = model_lgb.predict(x_val)\n",
    "subA_lgb = model_lgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sta inf of lgb:\n",
      "_min -280.7380240419688\n",
      "_max: 88782.1143044527\n",
      "_mean 5926.331254325851\n",
      "_ptp 89062.85232849467\n",
      "_std 7362.190662618817\n",
      "_var 54201851.3527517\n"
     ]
    }
   ],
   "source": [
    "print('Sta inf of lgb:')\n",
    "Sta_inf(subA_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）加权融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of Weighted of val: 730.6081856718638\n",
      "Sta inf:\n",
      "_min -88.85069199362046\n",
      "_max: 88247.67969943957\n",
      "_mean 5928.533940288071\n",
      "_ptp 88336.53039143319\n",
      "_std 7341.737087314087\n",
      "_var 53901103.45924313\n"
     ]
    }
   ],
   "source": [
    "def Weighted_method(test_pre1,test_pre2,test_pre3,w=[1/3,1/3,1/3]):\n",
    "    Weighted_result = w[0]*pd.Series(test_pre1)+w[1]*pd.Series(test_pre2)+w[2]*pd.Series(test_pre3)\n",
    "    return Weighted_result\n",
    "\n",
    "## Init the Weight\n",
    "w = [0.3,0.4,0.3]\n",
    "\n",
    "## 测试验证集准确度\n",
    "val_pre = Weighted_method(val_lgb,val_xgb,val_gbdt,w)\n",
    "MAE_Weighted = mean_absolute_error(y_val,val_pre)\n",
    "print('MAE of Weighted of val:',MAE_Weighted)\n",
    "\n",
    "## 预测数据部分\n",
    "subA = Weighted_method(subA_lgb,subA_xgb,subA_gbdt,w)\n",
    "print('Sta inf:')\n",
    "Sta_inf(subA)\n",
    "## 生成提交文件\n",
    "sub = pd.DataFrame()\n",
    "sub['SaleID'] = X_test.index\n",
    "sub['price'] = subA\n",
    "sub.to_csv('./sub_Weighted.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of lr: 2593.018995220566\n"
     ]
    }
   ],
   "source": [
    "## 与简单的LR（线性回归）进行对比\n",
    "val_lr_pred = model_lr.predict(x_val)\n",
    "MAE_lr = mean_absolute_error(y_val,val_lr_pred)\n",
    "print('MAE of lr:',MAE_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）Stacking融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starking\n",
    "\n",
    "## 第一层\n",
    "train_lgb_pred = model_lgb.predict(x_train)\n",
    "train_xgb_pred = model_xgb.predict(x_train)\n",
    "train_gbdt_pred = model_gbdt.predict(x_train)\n",
    "\n",
    "Strak_X_train = pd.DataFrame()\n",
    "Strak_X_train['Method_1'] = train_lgb_pred\n",
    "Strak_X_train['Method_2'] = train_xgb_pred\n",
    "Strak_X_train['Method_3'] = train_gbdt_pred\n",
    "\n",
    "Strak_X_val = pd.DataFrame()\n",
    "Strak_X_val['Method_1'] = val_lgb\n",
    "Strak_X_val['Method_2'] = val_xgb\n",
    "Strak_X_val['Method_3'] = val_gbdt\n",
    "\n",
    "Strak_X_test = pd.DataFrame()\n",
    "Strak_X_test['Method_1'] = subA_lgb\n",
    "Strak_X_test['Method_2'] = subA_xgb\n",
    "Strak_X_test['Method_3'] = subA_gbdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method_1</th>\n",
       "      <th>Method_2</th>\n",
       "      <th>Method_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40323.360674</td>\n",
       "      <td>38442.433594</td>\n",
       "      <td>37317.179439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>275.184319</td>\n",
       "      <td>327.227081</td>\n",
       "      <td>206.197173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6876.171916</td>\n",
       "      <td>7504.832520</td>\n",
       "      <td>7052.177040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11671.895851</td>\n",
       "      <td>11517.415039</td>\n",
       "      <td>11955.059527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>572.032387</td>\n",
       "      <td>561.744629</td>\n",
       "      <td>533.142129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Method_1      Method_2      Method_3\n",
       "0  40323.360674  38442.433594  37317.179439\n",
       "1    275.184319    327.227081    206.197173\n",
       "2   6876.171916   7504.832520   7052.177040\n",
       "3  11671.895851  11517.415039  11955.059527\n",
       "4    572.032387    561.744629    533.142129"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Strak_X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of Stacking-LR: 627.782076276947\n",
      "MAE of Stacking-LR: 719.8894663833835\n",
      "Predict Stacking-LR...\n"
     ]
    }
   ],
   "source": [
    "## level2-method \n",
    "model_lr_Stacking = build_model_lr(Strak_X_train,y_train)\n",
    "## 训练集\n",
    "train_pre_Stacking = model_lr_Stacking.predict(Strak_X_train)\n",
    "print('MAE of Stacking-LR:',mean_absolute_error(y_train,train_pre_Stacking))\n",
    "\n",
    "## 验证集\n",
    "val_pre_Stacking = model_lr_Stacking.predict(Strak_X_val)\n",
    "print('MAE of Stacking-LR:',mean_absolute_error(y_val,val_pre_Stacking))\n",
    "\n",
    "## 预测集\n",
    "print('Predict Stacking-LR...')\n",
    "subA_Stacking = model_lr_Stacking.predict(Strak_X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "subA_Stacking[subA_Stacking<10]=10  ## 去除过小的预测值\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['SaleID'] = TestA_data.SaleID\n",
    "sub['price'] = subA_Stacking\n",
    "sub.to_csv('./sub_Stacking.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sta inf:\n",
      "_min 10.0\n",
      "_max: 89112.82582581835\n",
      "_mean 5927.336826224908\n",
      "_ptp 89102.82582581835\n",
      "_std 7397.445879213381\n",
      "_var 54722205.535891026\n"
     ]
    }
   ],
   "source": [
    "print('Sta inf:')\n",
    "Sta_inf(subA_Stacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 经验总结\n",
    "比赛的融合这个问题，个人的看法来说其实涉及多个层面，也是提分和提升模型鲁棒性的一种重要方法：\n",
    "\n",
    "1）结果层面的融合，这种是最常见的融合方法，其可行的融合方法也有很多，比如根据结果的得分进行加权融合，还可以做Log，exp处理等。在做结果融合的时候，有一个很重要的条件是模型结果的得分要比较近似，然后结果的差异要比较大，这样的结果融合往往有比较好的效果提升。\n",
    "\n",
    "2）特征层面的融合，这个层面其实感觉不叫融合，准确说可以叫分割，很多时候如果我们用同种模型训练，可以把特征进行切分给不同的模型，然后在后面进行模型或者结果融合有时也能产生比较好的效果。\n",
    "\n",
    "3）模型层面的融合，模型层面的融合可能就涉及模型的堆叠和设计，比如加Staking层，部分模型的结果作为特征输入等，这些就需要多实验和思考了，基于模型层面的融合最好不同模型类型要有一定的差异，用同种模型不同的参数的收益一般是比较小的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:han] *",
   "language": "python",
   "name": "conda-env-han-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
